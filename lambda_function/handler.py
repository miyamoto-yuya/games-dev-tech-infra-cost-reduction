import boto3
import json
import os
import uuid
from collections import defaultdict
from datetime import datetime, timedelta, timezone


# MCP ã‚µãƒ¼ãƒãƒ¼è¨­å®š
MCP_RUNTIME_ARN = os.environ.get(
    "MCP_RUNTIME_ARN",
    "arn:aws:bedrock-agentcore:ap-northeast-1:935762823806:runtime/infra_cost_reduction_pricing_mcp-M4Abq6BZRK"
)


def call_mcp_tool(tool_name: str, arguments: dict) -> dict:
    """MCP ã‚µãƒ¼ãƒãƒ¼ã®ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™"""
    try:
        client = boto3.client('bedrock-agentcore', region_name='ap-northeast-1')
        
        payload = json.dumps({
            "jsonrpc": "2.0",
            "method": "tools/call",
            "params": {
                "name": tool_name,
                "arguments": arguments
            },
            "id": 1
        })
        
        response = client.invoke_agent_runtime(
            agentRuntimeArn=MCP_RUNTIME_ARN,
            runtimeSessionId=str(uuid.uuid4()),
            mcpSessionId=str(uuid.uuid4()),
            mcpProtocolVersion="2024-11-05",
            contentType="application/json",
            accept="application/json, text/event-stream",
            payload=payload.encode('utf-8')
        )
        
        content = []
        for chunk in response.get("response", []):
            content.append(chunk.decode('utf-8'))
        result = json.loads(''.join(content))
        
        if "result" in result and "content" in result["result"]:
            return json.loads(result["result"]["content"][0]["text"])
        return {"error": "Invalid response format"}
        
    except Exception as e:
        print(f"MCP call error: {e}")
        return {"error": str(e)}


def get_instance_price_from_mcp(instance_type: str, service: str = "ec2", region: str = "ap-northeast-1") -> float:
    """MCPã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä¾¡æ ¼ã‚’å–å¾—"""
    result = call_mcp_tool("get_instance_price", {
        "instance_type": instance_type,
        "service": service,
        "region": region
    })
    return result.get('hourly_price_usd') or result.get('hourly_price', 0.0)

# CloudWatchã‹ã‚‰æœ€å¤§CPUä½¿ç”¨ç‡ã‚’å–å¾—ï¼ˆ30æ—¥é–“ã€5åˆ†å¹³å‡ï¼‰
def get_max_cpu_utilization(instance_id, namespace='AWS/EC2', dimension_name='InstanceId'):
    cloudwatch = boto3.client('cloudwatch')

    period = 300  # 5åˆ†ã®æœŸé–“
    days = 30  # å–å¾—ã™ã‚‹æœŸé–“ï¼ˆ30æ—¥ï¼‰

    end_time = datetime.now(timezone.utc)
    start_time = end_time - timedelta(days=days)
    max_cpu = 0.0
    max_cpu_timestamp = None
    
    interval = timedelta(days=5)
    current_start = start_time

    while current_start < end_time:
        current_end = min(current_start + interval, end_time)

        response = cloudwatch.get_metric_statistics(
            Namespace=namespace,
            MetricName='CPUUtilization',
            Dimensions=[{'Name': dimension_name, 'Value': instance_id}],
            StartTime=current_start,
            EndTime=current_end,
            Period=period,
            Statistics=['Average'],
            Unit='Percent'
        )

        datapoints = response.get('Datapoints', [])

        for dp in datapoints:
            if dp['Average'] > max_cpu:
                max_cpu = dp['Average']
                max_cpu_timestamp = dp['Timestamp']

        current_start = current_end
    
    return (round(max_cpu, 2), max_cpu_timestamp) if max_cpu > 0 else (None, None)


def get_ec2_instances():
    ec2 = boto3.client("ec2")
    
    response = ec2.describe_instances()
    instances_info = []
    instance_data = defaultdict(lambda: {"count": 0, "ebs_info": set(), "instance_ids": [], "auto_scaling_group": None})

    for reservation in response["Reservations"]:
        for instance in reservation["Instances"]:
            if instance["State"]["Name"] in ["terminated", "stopped"]:
                continue
            
            instance_id = instance["InstanceId"]
            instance_type = instance["InstanceType"]
            
            instance_name = "N/A"
            for tag in instance.get("Tags", []):
                if tag["Key"] == "Name":
                    instance_name = tag["Value"]
                    break
            
            auto_scaling_group_name = None
            for tag in instance.get("Tags", []):
                if tag["Key"] == "aws:autoscaling:groupName":
                    auto_scaling_group_name = tag["Value"]
                    break
            
            key = (instance_name, instance_type)
            instance_data[key]["count"] += 1
            instance_data[key]["instance_ids"].append(instance_id)
            instance_data[key]["auto_scaling_group"] = auto_scaling_group_name
            
            for block_device in instance.get("BlockDeviceMappings", []):
                volume_id = block_device.get("Ebs", {}).get("VolumeId", "N/A")
                if volume_id != "N/A":
                    volume = ec2.describe_volumes(VolumeIds=[volume_id])["Volumes"][0]
                    ebs_type = volume["VolumeType"]
                    storage_size = volume["Size"]
                    instance_data[key]["ebs_info"].add((ebs_type, storage_size))
    
    for (instance_name, instance_type), data in instance_data.items():
        count = data["count"]
        ebs_info = data["ebs_info"]
        instance_ids = data["instance_ids"]
        auto_scaling_group_name = data["auto_scaling_group"]

        instance_id_display = instance_ids[0] if count == 1 else None

        max_cpu = 0.0
        max_cpu_timestamp = None

        if auto_scaling_group_name:
            max_cpu, max_cpu_timestamp = get_max_cpu_utilization(auto_scaling_group_name, namespace='AWS/EC2', dimension_name='AutoScalingGroupName')
        elif instance_ids:
            cpu_usages = [get_max_cpu_utilization(iid) for iid in instance_ids]
            for cpu, ts in cpu_usages:
                if cpu is not None and cpu > max_cpu:
                    max_cpu = cpu
                    max_cpu_timestamp = ts
        else:
            max_cpu = None
            max_cpu_timestamp = None

        if ebs_info:
            for ebs in ebs_info:
                instances_info.append({
                    "name": instance_name,
                    "instance_id": instance_id_display,
                    "instance_type": instance_type,
                    "count": count,
                    "ebs_type": ebs[0],
                    "ebs_size": ebs[1],
                    "max_cpu": max_cpu,
                    "max_cpu_time": max_cpu_timestamp.isoformat() if max_cpu_timestamp else None
                })

    return instances_info


def get_rds_clusters():
    rds = boto3.client("rds")
    clusters_info = []

    response = rds.describe_db_clusters()
    cluster_instance_ids = set()

    for cluster in response["DBClusters"]:
        if cluster["Engine"] == "docdb":
            continue
        cluster_name = cluster["DBClusterIdentifier"]
        node_count = len(cluster["DBClusterMembers"])

        instance_types = set()
        for member in cluster["DBClusterMembers"]:
            db_instance_identifier = member["DBInstanceIdentifier"]
            cluster_instance_ids.add(db_instance_identifier)
            db_instance = rds.describe_db_instances(DBInstanceIdentifier=db_instance_identifier)["DBInstances"][0]
            instance_type = db_instance["DBInstanceClass"]
            instance_types.add(instance_type)

        instance_type_display = ", ".join(sorted(instance_types)) if len(instance_types) > 1 else next(iter(instance_types))
        cpu, ts = get_max_cpu_utilization(cluster_name, namespace='AWS/RDS', dimension_name='DBClusterIdentifier')

        clusters_info.append({
            "name": cluster_name,
            "instance_type": instance_type_display,
            "count": node_count,
            "max_cpu": cpu,
            "max_cpu_time": ts.isoformat() if ts else None
        })

    response = rds.describe_db_instances()
    for instance in response["DBInstances"]:
        instance_id = instance["DBInstanceIdentifier"]
        if instance_id in cluster_instance_ids:
            continue

        if instance["Engine"] == "docdb":
            continue

        instance_type = instance["DBInstanceClass"]
        cpu, ts = get_max_cpu_utilization(instance_id, namespace='AWS/RDS', dimension_name='DBInstanceIdentifier')
        clusters_info.append({
            "name": instance_id,
            "instance_type": instance_type,
            "count": 1,
            "max_cpu": cpu,
            "max_cpu_time": ts.isoformat() if ts else None
        })

    return clusters_info


def get_docdb_clusters():
    docdb = boto3.client("docdb")
    response = docdb.describe_db_clusters()
    clusters_info = []
    
    for cluster in response["DBClusters"]:
        if cluster["Engine"] != "docdb":
            continue
        cluster_name = cluster["DBClusterIdentifier"]
        
        instance_types = set()
        for member in cluster["DBClusterMembers"]:
            db_instance_identifier = member["DBInstanceIdentifier"]
            db_instance = docdb.describe_db_instances(DBInstanceIdentifier=db_instance_identifier)["DBInstances"][0]
            instance_type = db_instance["DBInstanceClass"]
            instance_types.add(instance_type)
        
        instance_type_display = ", ".join(sorted(instance_types)) if len(instance_types) > 1 else next(iter(instance_types))
        
        node_count = len(cluster["DBClusterMembers"])
        cpu, ts = get_max_cpu_utilization(cluster_name, namespace='AWS/DocDB', dimension_name='DBClusterIdentifier')
        clusters_info.append({
            "name": cluster_name,
            "instance_type": instance_type_display,
            "count": node_count,
            "max_cpu": cpu,
            "max_cpu_time": ts.isoformat() if ts else None
        })
    
    return clusters_info


def get_redis_clusters():
    elasticache = boto3.client("elasticache")
    response = elasticache.describe_replication_groups()
    clusters_info = []

    for cluster in response["ReplicationGroups"]:
        cluster_name = cluster["ReplicationGroupId"]
        instance_type = cluster["CacheNodeType"]
        node_count = len(cluster["MemberClusters"])

        cpu = None
        ts = None
        for node_id in cluster["MemberClusters"]:
            cpu, ts = get_max_cpu_utilization(
                node_id,
                namespace='AWS/ElastiCache',
                dimension_name='CacheClusterId'
            )

        clusters_info.append({
            "name": cluster_name,
            "instance_type": instance_type,
            "count": node_count,
            "max_cpu": cpu,
            "max_cpu_time": ts.isoformat() if ts else None
        })

    return clusters_info


def get_memcache_clusters():
    elasticache = boto3.client("elasticache")
    response = elasticache.describe_cache_clusters()
    clusters_info = []

    for cluster in response["CacheClusters"]:
        if cluster["Engine"] != "memcached":
            continue
            
        cluster_name = cluster["CacheClusterId"]
        instance_type = cluster["CacheNodeType"]
        node_count = cluster["NumCacheNodes"]
        
        cpu, ts = get_max_cpu_utilization(
            cluster_name,
            namespace='AWS/ElastiCache',
            dimension_name='CacheClusterId'
        )

        clusters_info.append({
            "name": cluster_name,
            "instance_type": instance_type,
            "count": node_count,
            "max_cpu": cpu,
            "max_cpu_time": ts.isoformat() if ts else None
        })

    return clusters_info


def collect_all_resources():
    """ã™ã¹ã¦ã®AWSãƒªã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’åé›†"""
    return {
        "ec2": get_ec2_instances(),
        "rds": get_rds_clusters(),
        "docdb": get_docdb_clusters(),
        "redis": get_redis_clusters(),
        "memcache": get_memcache_clusters()
    }


def format_resources_for_bedrock(resources, pricing_info=None):
    """ãƒªã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’Bedrockç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«å¤‰æ›ï¼ˆä¾¡æ ¼æƒ…å ±å«ã‚€ï¼‰"""
    output = []
    
    # æ™‚é–“å˜ä¾¡ã‹ã‚‰æœˆé¡ã‚’è¨ˆç®—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼
    def get_monthly_cost(instance_type, service):
        if not pricing_info:
            return None
        service_key = 'elasticache' if service in ['redis', 'memcache'] else service
        prices = pricing_info.get(service_key, {})
        hourly = prices.get(instance_type, 0)
        return round(hourly * 730, 2) if hourly else None
    
    output.append("EC2 :")
    output.append("Instance Name\tInstance Type\tå°æ•°\tCPU AvgMax\tæœˆé¡(USD)")
    for item in resources["ec2"]:
        monthly = get_monthly_cost(item['instance_type'], 'ec2')
        monthly_str = f"${monthly}" if monthly else "N/A"
        output.append(f"{item['name']}\t{item['instance_type']}\t{item['count']}\t{item['max_cpu']}\t{monthly_str}")

    output.append("\nRDS :")
    output.append("Cluster Name\tInstance Type\tå°æ•°\tCPU AvgMax\tæœˆé¡(USD)")
    for item in resources["rds"]:
        monthly = get_monthly_cost(item['instance_type'], 'rds')
        monthly_str = f"${monthly}" if monthly else "N/A"
        output.append(f"{item['name']}\t{item['instance_type']}\t{item['count']}\t{item['max_cpu']}\t{monthly_str}")

    output.append("\nDocumentDB :")
    output.append("Cluster Name\tInstance Type\tå°æ•°\tCPU AvgMax\tæœˆé¡(USD)")
    for item in resources["docdb"]:
        monthly = get_monthly_cost(item['instance_type'], 'docdb')
        monthly_str = f"${monthly}" if monthly else "N/A"
        output.append(f"{item['name']}\t{item['instance_type']}\t{item['count']}\t{item['max_cpu']}\t{monthly_str}")

    output.append("\nRedis (ElastiCache) :")
    output.append("Cluster Name\tInstance Type\tå°æ•°\tCPU AvgMax\tæœˆé¡(USD)")
    for item in resources["redis"]:
        monthly = get_monthly_cost(item['instance_type'], 'redis')
        monthly_str = f"${monthly}" if monthly else "N/A"
        output.append(f"{item['name']}\t{item['instance_type']}\t{item['count']}\t{item['max_cpu']}\t{monthly_str}")

    output.append("\nMemcached (ElastiCache) :")
    output.append("Cluster Name\tInstance Type\tå°æ•°\tCPU AvgMax\tæœˆé¡(USD)")
    for item in resources["memcache"]:
        monthly = get_monthly_cost(item['instance_type'], 'memcache')
        monthly_str = f"${monthly}" if monthly else "N/A"
        output.append(f"{item['name']}\t{item['instance_type']}\t{item['count']}\t{item['max_cpu']}\t{monthly_str}")

    return "\n".join(output)


def collect_pricing_info(resources):
    """ãƒªã‚½ãƒ¼ã‚¹ã®ä¾¡æ ¼æƒ…å ±ã‚’åé›†ï¼ˆEC2/RDS/ElastiCache/DocDBï¼‰- é‡è¤‡ã‚¿ã‚¤ãƒ—ã¯1å›ã®ã¿å–å¾—"""
    pricing_info = {
        'ec2': {},
        'rds': {},
        'elasticache': {},
        'docdb': {}
    }
    
    # ã‚µãƒ¼ãƒ“ã‚¹ã¨ãƒªã‚½ãƒ¼ã‚¹ã‚­ãƒ¼ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    service_mapping = [
        ('ec2', 'ec2', resources.get("ec2", [])),
        ('rds', 'rds', resources.get("rds", [])),
        ('docdb', 'docdb', resources.get("docdb", [])),
        ('elasticache', 'redis', resources.get("redis", [])),
        ('elasticache', 'memcache', resources.get("memcache", [])),
    ]
    
    for service_key, resource_key, items in service_mapping:
        for item in items:
            instance_type = item.get("instance_type")
            if instance_type and instance_type not in pricing_info[service_key]:
                price = get_instance_price_from_mcp(instance_type, service_key)
                if price > 0:
                    pricing_info[service_key][instance_type] = price
    
    return pricing_info


def get_bedrock_analysis(resource_text):
    """Bedrockã«ãƒªã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’é€ä¿¡ã—ã¦åˆ†æã‚’å–å¾—ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚‚è¿”ã™ï¼‰"""
    bedrock_runtime = boto3.client("bedrock-runtime", region_name=os.environ.get("AWS_REGION_NAME", "ap-northeast-1"))
    model_id = os.environ.get("BEDROCK_MODEL_ID", "amazon.nova-lite-v1:0")

    prompt = f"""ã‚ãªãŸã¯AWSã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ã«ç‰¹åŒ–ã—ãŸææ¡ˆã‚’è¡Œã†AIã§ã™ã€‚

ä»¥ä¸‹ã«ã€ç¾åœ¨ã®EC2/RDS/DocDB/Redis/Memcachedã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æƒ…å ±ã¨ã€éå»30æ—¥é–“ã®CPUä½¿ç”¨ç‡ãƒ‡ãƒ¼ã‚¿ã‚’ç¤ºã—ã¾ã™ã€‚

ã€ãƒ‡ãƒ¼ã‚¿ã‚«ãƒ©ãƒ ã®èª¬æ˜ã€‘
- ã€ŒCPU AvgMaxã€åˆ—: éå»30æ—¥é–“ã®5åˆ†é–“å¹³å‡å€¤ã®æœ€å¤§ï¼ˆâ˜…åˆ¤å®šã«ä½¿ç”¨ï¼‰
- ã€ŒCPU Maxã€åˆ—: éå»30æ—¥é–“ã®5åˆ†é–“æœ€å¤§å€¤ã®æœ€å¤§ï¼ˆå‚è€ƒå€¤ï¼‰

---
{resource_text}
---

ã€åˆ¤æ–­åŸºæº–ã€‘â˜…â˜…â˜… å¿…ãšã€ŒCPU AvgMaxã€ã®å€¤ã®ã¿ã§åˆ¤å®š â˜…â˜…â˜…

| CPU AvgMax | åˆ¤å®š | ææ¡ˆ |
|------------|------|------|
| 30%æœªæº€ | éå‰° | å°ã•ã„ã‚¿ã‚¤ãƒ—ã¸å¤‰æ›´ï¼ˆã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼‰ |
| 30%ã€œ70% | é©æ­£ | å¤‰æ›´ä¸è¦ |
| 70%ä»¥ä¸Š | ä¸è¶³ | å¤‰æ›´ä¸è¦ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã®ã¿ï¼‰ |

â˜…â˜…â˜… é‡è¦ â˜…â˜…â˜…
- ã“ã‚Œã¯ã‚³ã‚¹ãƒˆå‰Šæ¸›ãƒ„ãƒ¼ãƒ«ã§ã™
- ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ï¼ˆå°ã•ã„ã‚¿ã‚¤ãƒ—ã¸ã®å¤‰æ›´ï¼‰ã®ã¿ææ¡ˆã—ã¦ãã ã•ã„
- ã‚¹ãƒšãƒƒã‚¯ä¸è¶³ã®å ´åˆã¯ã€Œå¤‰æ›´ä¸è¦ã€ã¨ã—ã€ã‚³ãƒ¡ãƒ³ãƒˆã§ã€Œã‚¹ãƒšãƒƒã‚¯ä¸è¶³ã€ã¨è¨˜è¼‰ã™ã‚‹ã ã‘ã§OK

ä¾‹ï¼š
- CPU AvgMax = 10% â†’ éå‰° â†’ t3.medium â†’ t3.small ã¸å¤‰æ›´ææ¡ˆ
- CPU AvgMax = 35% â†’ é©æ­£ â†’ å¤‰æ›´ä¸è¦
- CPU AvgMax = 80% â†’ ä¸è¶³ â†’ å¤‰æ›´ä¸è¦ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆï¼šã‚¹ãƒšãƒƒã‚¯ä¸è¶³ï¼‰

ã€å‡ºåŠ›å½¢å¼ã€‘
## ã‚µãƒãƒªãƒ¼
(ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®å¯èƒ½æ€§ã‚’1-2æ–‡ã§)

## è©³ç´°ææ¡ˆ

### EC2
- **ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å**: (åå‰)
  - ç¾åœ¨: (ã‚¿ã‚¤ãƒ—) / CPU AvgMax: (å€¤)%
  - åˆ¤å®š: (éå‰°/é©æ­£/ä¸è¶³)
  - ææ¡ˆ: (å°ã•ã„ã‚¿ã‚¤ãƒ— ã¾ãŸã¯ã€Œå¤‰æ›´ä¸è¦ã€)

### RDS
(åŒæ§˜)

### DocumentDB
(åŒæ§˜)

### Redis (ElastiCache)
(åŒæ§˜)

### Memcached (ElastiCache)
(åŒæ§˜)

â€» è©²å½“ãƒªã‚½ãƒ¼ã‚¹ãŒãªã„å ´åˆã¯ã€Œãªã—ã€ã¨è¨˜è¼‰
"""

    # ãƒ¢ãƒ‡ãƒ«IDã«å¿œã˜ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆå½¢å¼ã‚’åˆ‡ã‚Šæ›¿ãˆ
    if model_id.startswith("amazon.nova"):
        # Amazon Novaå½¢å¼
        request_body = {
            "messages": [
                {
                    "role": "user",
                    "content": [{"text": prompt}]
                }
            ],
            "inferenceConfig": {
                "maxTokens": 4000,
                "temperature": 0.7
            }
        }
    elif model_id.startswith("amazon.titan"):
        # Amazon Titanå½¢å¼
        request_body = {
            "inputText": prompt,
            "textGenerationConfig": {
                "maxTokenCount": 2000,
                "temperature": 0.7
            }
        }
    elif "anthropic" in model_id or "claude" in model_id:
        # Anthropic Claudeå½¢å¼
        request_body = {
            "messages": [
                {
                    "role": "user",
                    "content": [{"type": "text", "text": prompt}]
                }
            ],
            "max_tokens": 2000,
            "anthropic_version": "bedrock-2023-05-31",
            "temperature": 0.7
        }
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆNovaå½¢å¼ï¼‰
        request_body = {
            "messages": [
                {
                    "role": "user",
                    "content": [{"text": prompt}]
                }
            ],
            "inferenceConfig": {
                "maxTokens": 4000,
                "temperature": 0.7
            }
        }

    response = bedrock_runtime.invoke_model(
        modelId=model_id,
        body=json.dumps(request_body),
        contentType='application/json',
        accept='application/json'
    )

    response_body = json.loads(response['body'].read())
    
    # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’å–å¾—ï¼ˆNovaå½¢å¼ï¼‰
    usage = response_body.get('usage', {})
    input_tokens = usage.get('inputTokens', 0)
    output_tokens = usage.get('outputTokens', 0)
    
    # Nova Lite ã®æ–™é‡‘ï¼ˆUSD / 1K tokensï¼‰- ap-northeast-1
    INPUT_PRICE_PER_1K = 0.00006   # $0.06 / 1M tokens
    OUTPUT_PRICE_PER_1K = 0.00024  # $0.24 / 1M tokens
    
    input_cost = (input_tokens / 1000) * INPUT_PRICE_PER_1K
    output_cost = (output_tokens / 1000) * OUTPUT_PRICE_PER_1K
    total_cost = input_cost + output_cost
    
    token_info = {
        "model_id": model_id,
        "input_tokens": input_tokens,
        "output_tokens": output_tokens,
        "total_tokens": input_tokens + output_tokens,
        "input_cost_usd": round(input_cost, 6),
        "output_cost_usd": round(output_cost, 6),
        "total_cost_usd": round(total_cost, 6),
        "total_cost_jpy": round(total_cost * 150, 4)  # æ¦‚ç®—ãƒ¬ãƒ¼ãƒˆ
    }
    
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã«å¿œã˜ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
    if model_id.startswith("amazon.nova"):
        analysis_text = response_body['output']['message']['content'][0]['text']
    elif model_id.startswith("amazon.titan"):
        analysis_text = response_body['results'][0]['outputText']
    elif "anthropic" in model_id or "claude" in model_id:
        analysis_text = response_body['content'][0]['text']
    else:
        analysis_text = response_body.get('output', {}).get('message', {}).get('content', [{}])[0].get('text', str(response_body))
    
    return {
        "text": analysis_text,
        "token_usage": token_info
    }


def get_cloudshell_script():
    """CloudShellç”¨ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’è¿”ã™"""
    return '''#!/usr/bin/env python3
"""
AWS ã‚¤ãƒ³ãƒ•ãƒ©ã‚³ã‚¹ãƒˆå‰Šæ¸›ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ - CloudShell ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
AWS CloudShell ã§å®Ÿè¡Œã—ã¦ã€çµæœã‚’ã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆã—ã¦ãã ã•ã„ã€‚
"""

import boto3
from collections import defaultdict
from datetime import datetime, timedelta, timezone
import sys

def get_max_cpu_utilization(instance_id, namespace='AWS/EC2', dimension_name='InstanceId'):
    cloudwatch = boto3.client('cloudwatch')
    period = 300
    days = 30
    end_time = datetime.now(timezone.utc)
    start_time = end_time - timedelta(days=days)
    max_cpu = 0.0
    max_cpu_timestamp = None
    interval = timedelta(days=5)
    current_start = start_time

    while current_start < end_time:
        current_end = min(current_start + interval, end_time)
        try:
            response = cloudwatch.get_metric_statistics(
                Namespace=namespace,
                MetricName='CPUUtilization',
                Dimensions=[{'Name': dimension_name, 'Value': instance_id}],
                StartTime=current_start,
                EndTime=current_end,
                Period=period,
                Statistics=['Average'],
                Unit='Percent'
            )
            for dp in response.get('Datapoints', []):
                if dp['Average'] > max_cpu:
                    max_cpu = dp['Average']
                    max_cpu_timestamp = dp['Timestamp']
        except Exception:
            pass
        current_start = current_end
    
    return (round(max_cpu, 2), max_cpu_timestamp) if max_cpu > 0 else (None, None)


def get_ec2_instances():
    ec2 = boto3.client("ec2")
    response = ec2.describe_instances()
    instances_info = []
    instance_data = defaultdict(lambda: {"count": 0, "ebs_info": set(), "instance_ids": [], "auto_scaling_group": None})

    for reservation in response["Reservations"]:
        for instance in reservation["Instances"]:
            if instance["State"]["Name"] in ["terminated", "stopped"]:
                continue
            
            instance_id = instance["InstanceId"]
            instance_type = instance["InstanceType"]
            
            instance_name = "N/A"
            for tag in instance.get("Tags", []):
                if tag["Key"] == "Name":
                    instance_name = tag["Value"]
                    break
            
            auto_scaling_group_name = None
            for tag in instance.get("Tags", []):
                if tag["Key"] == "aws:autoscaling:groupName":
                    auto_scaling_group_name = tag["Value"]
                    break
            
            key = (instance_name, instance_type)
            instance_data[key]["count"] += 1
            instance_data[key]["instance_ids"].append(instance_id)
            instance_data[key]["auto_scaling_group"] = auto_scaling_group_name
            
            for block_device in instance.get("BlockDeviceMappings", []):
                volume_id = block_device.get("Ebs", {}).get("VolumeId", "N/A")
                if volume_id != "N/A":
                    try:
                        volume = ec2.describe_volumes(VolumeIds=[volume_id])["Volumes"][0]
                        ebs_type = volume["VolumeType"]
                        storage_size = volume["Size"]
                        instance_data[key]["ebs_info"].add((ebs_type, storage_size))
                    except Exception:
                        pass
    
    for (instance_name, instance_type), data in instance_data.items():
        count = data["count"]
        ebs_info = data["ebs_info"]
        instance_ids = data["instance_ids"]
        auto_scaling_group_name = data["auto_scaling_group"]
        instance_id_display = instance_ids[0] if count == 1 else None

        max_cpu = 0.0
        max_cpu_timestamp = None

        if auto_scaling_group_name:
            max_cpu, max_cpu_timestamp = get_max_cpu_utilization(auto_scaling_group_name, namespace='AWS/EC2', dimension_name='AutoScalingGroupName')
        elif instance_ids:
            for iid in instance_ids:
                cpu, ts = get_max_cpu_utilization(iid)
                if cpu is not None and cpu > max_cpu:
                    max_cpu = cpu
                    max_cpu_timestamp = ts

        if ebs_info:
            for ebs in ebs_info:
                instances_info.append([
                    instance_name, instance_id_display, instance_type, count,
                    ebs[0], ebs[1], max_cpu,
                    max_cpu_timestamp.isoformat() if max_cpu_timestamp else "N/A"
                ])

    return instances_info


def get_rds_clusters():
    rds = boto3.client("rds")
    clusters_info = []
    cluster_instance_ids = set()

    try:
        response = rds.describe_db_clusters()
        for cluster in response["DBClusters"]:
            if cluster["Engine"] == "docdb":
                continue
            cluster_name = cluster["DBClusterIdentifier"]
            node_count = len(cluster["DBClusterMembers"])

            instance_types = set()
            for member in cluster["DBClusterMembers"]:
                db_instance_identifier = member["DBInstanceIdentifier"]
                cluster_instance_ids.add(db_instance_identifier)
                db_instance = rds.describe_db_instances(DBInstanceIdentifier=db_instance_identifier)["DBInstances"][0]
                instance_type = db_instance["DBInstanceClass"]
                instance_types.add(instance_type)

            instance_type_display = ", ".join(sorted(instance_types)) if len(instance_types) > 1 else next(iter(instance_types))
            cpu, ts = get_max_cpu_utilization(cluster_name, namespace='AWS/RDS', dimension_name='DBClusterIdentifier')
            clusters_info.append([cluster_name, instance_type_display, node_count, cpu, ts.isoformat() if ts else None])
    except Exception:
        pass

    try:
        response = rds.describe_db_instances()
        for instance in response["DBInstances"]:
            instance_id = instance["DBInstanceIdentifier"]
            if instance_id in cluster_instance_ids or instance["Engine"] == "docdb":
                continue
            instance_type = instance["DBInstanceClass"]
            cpu, ts = get_max_cpu_utilization(instance_id, namespace='AWS/RDS', dimension_name='DBInstanceIdentifier')
            clusters_info.append([instance_id, instance_type, 1, cpu, ts.isoformat() if ts else None])
    except Exception:
        pass

    return clusters_info


def get_docdb_clusters():
    docdb = boto3.client("docdb")
    clusters_info = []
    
    try:
        response = docdb.describe_db_clusters()
        for cluster in response["DBClusters"]:
            if cluster["Engine"] != "docdb":
                continue
            cluster_name = cluster["DBClusterIdentifier"]
            
            instance_types = set()
            for member in cluster["DBClusterMembers"]:
                db_instance_identifier = member["DBInstanceIdentifier"]
                db_instance = docdb.describe_db_instances(DBInstanceIdentifier=db_instance_identifier)["DBInstances"][0]
                instance_type = db_instance["DBInstanceClass"]
                instance_types.add(instance_type)
            
            instance_type_display = ", ".join(sorted(instance_types)) if len(instance_types) > 1 else next(iter(instance_types))
            node_count = len(cluster["DBClusterMembers"])
            cpu, ts = get_max_cpu_utilization(cluster_name, namespace='AWS/DocDB', dimension_name='DBClusterIdentifier')
            clusters_info.append([cluster_name, instance_type_display, node_count, cpu, ts.isoformat() if ts else None])
    except Exception:
        pass
    
    return clusters_info


def get_redis_clusters():
    elasticache = boto3.client("elasticache")
    clusters_info = []

    try:
        response = elasticache.describe_replication_groups()
        for cluster in response["ReplicationGroups"]:
            cluster_name = cluster["ReplicationGroupId"]
            instance_type = cluster["CacheNodeType"]
            node_count = len(cluster["MemberClusters"])
            cpu, ts = None, None
            for node_id in cluster["MemberClusters"]:
                cpu, ts = get_max_cpu_utilization(node_id, namespace='AWS/ElastiCache', dimension_name='CacheClusterId')
            clusters_info.append([cluster_name, instance_type, node_count, cpu, ts.isoformat() if ts else None])
    except Exception:
        pass

    return clusters_info


def get_memcache_clusters():
    elasticache = boto3.client("elasticache")
    clusters_info = []

    try:
        response = elasticache.describe_cache_clusters()
        for cluster in response["CacheClusters"]:
            if cluster["Engine"] != "memcached":
                continue
            cluster_name = cluster["CacheClusterId"]
            instance_type = cluster["CacheNodeType"]
            node_count = cluster["NumCacheNodes"]
            cpu, ts = get_max_cpu_utilization(cluster_name, namespace='AWS/ElastiCache', dimension_name='CacheClusterId')
            clusters_info.append([cluster_name, instance_type, node_count, cpu, ts.isoformat() if ts else None])
    except Exception:
        pass

    return clusters_info


def main():
    print("=" * 60, file=sys.stderr)
    print("AWS ã‚¤ãƒ³ãƒ•ãƒ©ã‚³ã‚¹ãƒˆå‰Šæ¸›ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼", file=sys.stderr)
    print("=" * 60, file=sys.stderr)
    print("ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­...", file=sys.stderr)
    
    ec2_instances = get_ec2_instances()
    print(f"  EC2: {len(ec2_instances)} ä»¶", file=sys.stderr)
    
    rds_clusters = get_rds_clusters()
    print(f"  RDS: {len(rds_clusters)} ä»¶", file=sys.stderr)
    
    docdb_clusters = get_docdb_clusters()
    print(f"  DocumentDB: {len(docdb_clusters)} ä»¶", file=sys.stderr)
    
    redis_clusters = get_redis_clusters()
    print(f"  Redis: {len(redis_clusters)} ä»¶", file=sys.stderr)
    
    memcache_clusters = get_memcache_clusters()
    print(f"  Memcached: {len(memcache_clusters)} ä»¶", file=sys.stderr)
    
    print("", file=sys.stderr)
    print("=" * 60, file=sys.stderr)
    print("ä»¥ä¸‹ã®çµæœã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã«è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„", file=sys.stderr)
    print("=" * 60, file=sys.stderr)
    print("", file=sys.stderr)

    print("\\nEC2 :")
    print("Instance Name\\tInstance ID\\tInstance Type\\tå°æ•°\\tEBS Type\\tEBS Size\\tMax CPU\\tMax CPU Time")
    for instance in ec2_instances:
        print("\\t".join(map(str, instance)))

    print("\\nRedis :")
    print("Cluster Name\\tInstance Type\\tå°æ•°\\tMax CPU\\tMax CPU Time")
    for cluster in redis_clusters:
        print("\\t".join(map(str, cluster)))

    print("\\nMemcached :")
    print("Cluster Name\\tInstance Type\\tå°æ•°\\tMax CPU\\tMax CPU Time")
    for cluster in memcache_clusters:
        print("\\t".join(map(str, cluster)))

    print("\\nRDS :")
    print("Cluster Name\\tInstance Type\\tå°æ•°\\tMax CPU\\tMax CPU Time")
    for cluster in rds_clusters:
        print("\\t".join(map(str, cluster)))

    print("\\nDocumentDB :")
    print("Cluster Name\\tInstance Type\\tå°æ•°\\tMax CPU\\tMax CPU Time")
    for cluster in docdb_clusters:
        print("\\t".join(map(str, cluster)))


if __name__ == "__main__":
    main()
'''


def get_local_check_script():
    """ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œç”¨ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’è¿”ã™ï¼ˆAWS CLIãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ + è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰"""
    # å‹•çš„ã«URLã‚’åŸ‹ã‚è¾¼ã‚€
    return '''#!/usr/bin/env python3
"""
AWS ã‚¤ãƒ³ãƒ•ãƒ©ã‚³ã‚¹ãƒˆå‰Šæ¸›ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ - ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨æ–¹æ³•:
  # è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ + AIåˆ†æï¼ˆæ¨å¥¨ï¼‰
  python check.py --profile account-a --upload --analyze
  
  # è¤‡æ•°ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä¸€æ‹¬å‡¦ç†
  for p in account-a account-b account-c; do
    python check.py --profile $p --upload --analyze
  done
  
  # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
  python check.py --profile account-a --output result.txt
"""
import boto3
import argparse
import sys
import io
import json
from urllib.request import urlopen, Request
from urllib.error import URLError, HTTPError
from collections import defaultdict
from datetime import datetime, timedelta, timezone

DEFAULT_URL = "https://oprto2mpbwtacfhzaql7phb5ay0rxifk.lambda-url.ap-northeast-1.on.aws/"
_session = None

def get_session():
    global _session
    if _session is None:
        _session = boto3.Session()
    return _session

def get_client(service_name):
    return get_session().client(service_name)

def get_max_cpu_utilization(instance_id, namespace='AWS/EC2', dimension_name='InstanceId'):
    cloudwatch = get_client('cloudwatch')
    period, days = 300, 30
    end_time = datetime.now(timezone.utc)
    start_time = end_time - timedelta(days=days)
    max_cpu, max_cpu_timestamp = 0.0, None
    interval = timedelta(days=5)
    current_start = start_time
    while current_start < end_time:
        current_end = min(current_start + interval, end_time)
        response = cloudwatch.get_metric_statistics(
            Namespace=namespace, MetricName='CPUUtilization',
            Dimensions=[{'Name': dimension_name, 'Value': instance_id}],
            StartTime=current_start, EndTime=current_end,
            Period=period, Statistics=['Average'], Unit='Percent'
        )
        for dp in response.get('Datapoints', []):
            if dp['Average'] > max_cpu:
                max_cpu, max_cpu_timestamp = dp['Average'], dp['Timestamp']
        current_start = current_end
    return (round(max_cpu, 2), max_cpu_timestamp) if max_cpu > 0 else (None, None)

def get_ec2_instances():
    ec2 = get_client("ec2")
    response = ec2.describe_instances()
    instances_info = []
    instance_data = defaultdict(lambda: {"count": 0, "ebs_info": set(), "instance_ids": [], "asg": None})
    for reservation in response["Reservations"]:
        for inst in reservation["Instances"]:
            if inst["State"]["Name"] in ["terminated", "stopped"]: continue
            iid, itype = inst["InstanceId"], inst["InstanceType"]
            name, asg = "N/A", None
            for tag in inst.get("Tags", []):
                if tag["Key"] == "Name": name = tag["Value"]
                if tag["Key"] == "aws:autoscaling:groupName": asg = tag["Value"]
            key = (name, itype)
            instance_data[key]["count"] += 1
            instance_data[key]["instance_ids"].append(iid)
            instance_data[key]["asg"] = asg
            for bd in inst.get("BlockDeviceMappings", []):
                vid = bd.get("Ebs", {}).get("VolumeId")
                if vid:
                    vol = ec2.describe_volumes(VolumeIds=[vid])["Volumes"][0]
                    instance_data[key]["ebs_info"].add((vol["VolumeType"], vol["Size"]))
    for (name, itype), data in instance_data.items():
        ids = data["instance_ids"]
        id_disp = ids[0] if data["count"] == 1 else None
        max_cpu, max_ts = None, None
        if data["asg"]:
            max_cpu, max_ts = get_max_cpu_utilization(data["asg"], 'AWS/EC2', 'AutoScalingGroupName')
        elif ids:
            for i in ids:
                c, t = get_max_cpu_utilization(i)
                if c and (max_cpu is None or c > max_cpu): max_cpu, max_ts = c, t
        for ebs in data["ebs_info"] or [(None, None)]:
            instances_info.append([name, id_disp, itype, data["count"], ebs[0], ebs[1], max_cpu, max_ts.isoformat() if max_ts else "N/A"])
    return instances_info

def get_rds_clusters():
    rds = get_client("rds")
    info, seen = [], set()
    for c in rds.describe_db_clusters()["DBClusters"]:
        if c["Engine"] == "docdb": continue
        types = set()
        for m in c["DBClusterMembers"]:
            seen.add(m["DBInstanceIdentifier"])
            types.add(rds.describe_db_instances(DBInstanceIdentifier=m["DBInstanceIdentifier"])["DBInstances"][0]["DBInstanceClass"])
        cpu, ts = get_max_cpu_utilization(c["DBClusterIdentifier"], 'AWS/RDS', 'DBClusterIdentifier')
        info.append([c["DBClusterIdentifier"], ", ".join(sorted(types)), len(c["DBClusterMembers"]), cpu, ts.isoformat() if ts else None])
    for i in rds.describe_db_instances()["DBInstances"]:
        if i["DBInstanceIdentifier"] in seen or i["Engine"] == "docdb": continue
        cpu, ts = get_max_cpu_utilization(i["DBInstanceIdentifier"], 'AWS/RDS', 'DBInstanceIdentifier')
        info.append([i["DBInstanceIdentifier"], i["DBInstanceClass"], 1, cpu, ts.isoformat() if ts else None])
    return info

def get_docdb_clusters():
    docdb = get_client("docdb")
    info = []
    for c in docdb.describe_db_clusters()["DBClusters"]:
        if c["Engine"] != "docdb": continue
        types = set()
        for m in c["DBClusterMembers"]:
            types.add(docdb.describe_db_instances(DBInstanceIdentifier=m["DBInstanceIdentifier"])["DBInstances"][0]["DBInstanceClass"])
        cpu, ts = get_max_cpu_utilization(c["DBClusterIdentifier"], 'AWS/DocDB', 'DBClusterIdentifier')
        info.append([c["DBClusterIdentifier"], ", ".join(sorted(types)), len(c["DBClusterMembers"]), cpu, ts.isoformat() if ts else None])
    return info

def get_redis_clusters():
    ec = get_client("elasticache")
    info = []
    for c in ec.describe_replication_groups()["ReplicationGroups"]:
        cpu, ts = None, None
        for n in c["MemberClusters"]:
            cpu, ts = get_max_cpu_utilization(n, 'AWS/ElastiCache', 'CacheClusterId')
        info.append([c["ReplicationGroupId"], c["CacheNodeType"], len(c["MemberClusters"]), cpu, ts.isoformat() if ts else None])
    return info

def get_memcache_clusters():
    ec = get_client("elasticache")
    info = []
    for c in ec.describe_cache_clusters()["CacheClusters"]:
        if c["Engine"] != "memcached": continue
        cpu, ts = get_max_cpu_utilization(c["CacheClusterId"], 'AWS/ElastiCache', 'CacheClusterId')
        info.append([c["CacheClusterId"], c["CacheNodeType"], c["NumCacheNodes"], cpu, ts.isoformat() if ts else None])
    return info

def output_results(ec2, rds, docdb, redis, memcache, file=None):
    out = file or sys.stdout
    print("\\nEC2 :", file=out)
    print("Instance Name\\tInstance ID\\tInstance Type\\tå°æ•°\\tEBS Type\\tEBS Size\\tMax CPU\\tMax CPU Time", file=out)
    for i in ec2: print("\\t".join(map(str, i)), file=out)
    print("\\nRedis :", file=out)
    print("Cluster Name\\tInstance Type\\tå°æ•°\\tMax CPU\\tMax CPU Time", file=out)
    for c in redis: print("\\t".join(map(str, c)), file=out)
    print("\\nMemcached :", file=out)
    print("Cluster Name\\tInstance Type\\tå°æ•°\\tMax CPU\\tMax CPU Time", file=out)
    for c in memcache: print("\\t".join(map(str, c)), file=out)
    print("\\nRDS :", file=out)
    print("Cluster Name\\tInstance Type\\tå°æ•°\\tMax CPU\\tMax CPU Time", file=out)
    for c in rds: print("\\t".join(map(str, c)), file=out)
    print("\\nDocumentDB :", file=out)
    print("Cluster Name\\tInstance Type\\tå°æ•°\\tMax CPU\\tMax CPU Time", file=out)
    for c in docdb: print("\\t".join(map(str, c)), file=out)

def get_result_text(ec2, rds, docdb, redis, memcache):
    buf = io.StringIO()
    output_results(ec2, rds, docdb, redis, memcache, file=buf)
    return buf.getvalue()

def upload(text, url, analyze=False):
    data = json.dumps({"action": "analyze_text" if analyze else "upload_only", "resource_text": text}).encode()
    req = Request(url, data=data, headers={"Content-Type": "application/json"}, method="POST")
    try:
        with urlopen(req, timeout=120) as r:
            return json.loads(r.read().decode())
    except Exception as e:
        return {"error": str(e)}

def log(msg, quiet=False):
    if not quiet: print(msg, file=sys.stderr)

def main():
    parser = argparse.ArgumentParser(description='AWS ã‚¤ãƒ³ãƒ•ãƒ©ãƒªã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’åé›†ãƒ»åˆ†æ')
    parser.add_argument('--profile', '-p', type=str, help='AWSãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å')
    parser.add_argument('--output', '-o', type=str, help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å')
    parser.add_argument('--stdout', '-s', action='store_true', help='æ¨™æº–å‡ºåŠ›ã«å‡ºåŠ›')
    parser.add_argument('--upload', '-u', action='store_true', help='ã‚µãƒ¼ãƒãƒ¼ã«è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰')
    parser.add_argument('--analyze', '-a', action='store_true', help='AIåˆ†æã‚‚å®Ÿè¡Œ')
    parser.add_argument('--url', type=str, default=DEFAULT_URL, help='ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…ˆURL')
    parser.add_argument('--region', '-r', type=str, help='AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³')
    parser.add_argument('--quiet', '-q', action='store_true', help='é€²æ—éè¡¨ç¤º')
    args = parser.parse_args()
    
    global _session
    quiet = args.quiet or args.stdout
    
    if args.profile:
        _session = boto3.Session(profile_name=args.profile, region_name=args.region) if args.region else boto3.Session(profile_name=args.profile)
        log(f"Using profile: {args.profile}", quiet)
    elif args.region:
        _session = boto3.Session(region_name=args.region)
    
    log("Collecting...", quiet)
    ec2 = get_ec2_instances(); log(f"  EC2: {len(ec2)}", quiet)
    rds = get_rds_clusters(); log(f"  RDS: {len(rds)}", quiet)
    docdb = get_docdb_clusters(); log(f"  DocDB: {len(docdb)}", quiet)
    redis = get_redis_clusters(); log(f"  Redis: {len(redis)}", quiet)
    memcache = get_memcache_clusters(); log(f"  Memcache: {len(memcache)}", quiet)
    
    text = get_result_text(ec2, rds, docdb, redis, memcache)

    if args.upload:
        log(f"Uploading to {args.url}...", quiet)
        res = upload(text, args.url, args.analyze)
        if "error" in res:
            log(f"âŒ Error: {res['error']}", False)
            sys.exit(1)
        log("âœ… Upload successful!", quiet)
        if args.analyze and "analysis" in res:
            print("\\n" + "="*60 + "\\nğŸ¤– AI ã‚µã‚¤ã‚¸ãƒ³ã‚°ææ¡ˆ\\n" + "="*60 + "\\n")
            print(res["analysis"])
        if args.output:
            with open(args.output, "w") as f:
                f.write(text)
                if args.analyze and "analysis" in res:
                    f.write("\\n\\n" + res["analysis"])
            log(f"Also saved: {args.output}", quiet)
    elif args.stdout:
        output_results(ec2, rds, docdb, redis, memcache)
    elif args.output:
        with open(args.output, "w") as f:
            output_results(ec2, rds, docdb, redis, memcache, file=f)
        log(f"Saved: {args.output}", quiet)
    else:
        with open("output.txt", "w") as f:
            output_results(ec2, rds, docdb, redis, memcache, file=f)
        log("Saved: output.txt", quiet)

if __name__ == "__main__":
    main()
'''


def get_html_template():
    """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰HTMLã‚’è¿”ã™"""
    return '''<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AWS ã‚¤ãƒ³ãƒ•ãƒ©ã‚³ã‚¹ãƒˆå‰Šæ¸›ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼</title>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@300;400;500;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg-primary: #0a0f1a;
            --bg-secondary: #111827;
            --bg-card: #1a2332;
            --text-primary: #f0f4f8;
            --text-secondary: #94a3b8;
            --accent-cyan: #22d3ee;
            --accent-orange: #fb923c;
            --accent-green: #4ade80;
            --accent-red: #f87171;
            --accent-purple: #a78bfa;
            --border-color: #2d3a4f;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Noto Sans JP', sans-serif;
            background: var(--bg-primary);
            color: var(--text-primary);
            min-height: 100vh;
            background-image: 
                radial-gradient(ellipse at 10% 20%, rgba(34, 211, 238, 0.08) 0%, transparent 50%),
                radial-gradient(ellipse at 90% 80%, rgba(251, 146, 60, 0.08) 0%, transparent 50%),
                linear-gradient(180deg, var(--bg-primary) 0%, var(--bg-secondary) 100%);
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 2rem;
        }

        header {
            text-align: center;
            margin-bottom: 3rem;
            animation: fadeInDown 0.6s ease-out;
        }

        @keyframes fadeInDown {
            from { opacity: 0; transform: translateY(-20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        @keyframes fadeInUp {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .logo {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 1rem;
            margin-bottom: 1rem;
        }

        .logo-icon {
            width: 60px;
            height: 60px;
            background: linear-gradient(135deg, var(--accent-cyan), var(--accent-orange));
            border-radius: 16px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.8rem;
            box-shadow: 0 8px 32px rgba(34, 211, 238, 0.3);
        }

        h1 {
            font-size: 2.5rem;
            font-weight: 700;
            background: linear-gradient(135deg, var(--accent-cyan), var(--accent-orange));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .subtitle {
            color: var(--text-secondary);
            font-size: 1.1rem;
            margin-top: 0.5rem;
        }

        .main-card {
            background: var(--bg-card);
            border-radius: 20px;
            border: 1px solid var(--border-color);
            padding: 2rem;
            margin-bottom: 2rem;
            animation: fadeInUp 0.6s ease-out 0.2s both;
        }

        .button-group {
            display: flex;
            gap: 1rem;
            justify-content: center;
            flex-wrap: wrap;
        }

        .btn {
            padding: 1rem 2rem;
            border: none;
            border-radius: 12px;
            font-size: 1rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            font-family: inherit;
        }

        .btn-primary {
            background: linear-gradient(135deg, var(--accent-cyan), #06b6d4);
            color: var(--bg-primary);
            box-shadow: 0 4px 20px rgba(34, 211, 238, 0.3);
        }

        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 30px rgba(34, 211, 238, 0.4);
        }

        .btn-secondary {
            background: var(--bg-secondary);
            color: var(--text-primary);
            border: 1px solid var(--border-color);
        }

        .btn-secondary:hover {
            border-color: var(--accent-cyan);
            background: rgba(34, 211, 238, 0.1);
        }

        .btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }

        .tab-btn {
            padding: 0.75rem 1.5rem;
            border: 1px solid var(--border-color);
            border-radius: 8px;
            background: var(--bg-secondary);
            color: var(--text-secondary);
            font-size: 0.9rem;
            cursor: pointer;
            transition: all 0.2s ease;
            font-family: inherit;
        }

        .tab-btn:hover {
            border-color: var(--accent-cyan);
            color: var(--text-primary);
        }

        .tab-btn.active {
            background: linear-gradient(135deg, rgba(34, 211, 238, 0.2), rgba(251, 146, 60, 0.2));
            border-color: var(--accent-cyan);
            color: var(--text-primary);
        }

        .status-bar {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 0.75rem;
            padding: 1rem;
            margin-top: 1.5rem;
            border-radius: 10px;
            background: var(--bg-secondary);
            font-size: 0.95rem;
        }

        .status-bar.loading {
            color: var(--accent-cyan);
        }

        .status-bar.success {
            color: var(--accent-green);
        }

        .status-bar.error {
            color: var(--accent-red);
        }

        .spinner {
            width: 20px;
            height: 20px;
            border: 2px solid transparent;
            border-top-color: currentColor;
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        .results-section {
            display: none;
            animation: fadeInUp 0.6s ease-out;
        }

        .results-section.visible {
            display: block;
        }

        .section-title {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.75rem;
            color: var(--text-primary);
        }

        .section-title .icon {
            width: 32px;
            height: 32px;
            border-radius: 8px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1rem;
        }

        .section-title .icon.ec2 { background: rgba(34, 211, 238, 0.2); }
        .section-title .icon.rds { background: rgba(251, 146, 60, 0.2); }
        .section-title .icon.redis { background: rgba(248, 113, 113, 0.2); }
        .section-title .icon.docdb { background: rgba(74, 222, 128, 0.2); }
        .section-title .icon.memcache { background: rgba(167, 139, 250, 0.2); }

        .data-table {
            width: 100%;
            border-collapse: collapse;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.85rem;
        }

        .data-table th {
            background: var(--bg-secondary);
            padding: 0.75rem 1rem;
            text-align: left;
            font-weight: 500;
            color: var(--text-secondary);
            border-bottom: 2px solid var(--border-color);
            white-space: nowrap;
        }

        .data-table td {
            padding: 0.75rem 1rem;
            border-bottom: 1px solid var(--border-color);
        }

        .data-table tr:hover {
            background: rgba(34, 211, 238, 0.05);
        }

        .cpu-badge {
            display: inline-block;
            padding: 0.25rem 0.75rem;
            border-radius: 20px;
            font-weight: 500;
            font-size: 0.8rem;
        }

        .cpu-low { background: rgba(74, 222, 128, 0.2); color: var(--accent-green); }
        .cpu-medium { background: rgba(251, 146, 60, 0.2); color: var(--accent-orange); }
        .cpu-high { background: rgba(248, 113, 113, 0.2); color: var(--accent-red); }

        /* ã‚³ã‚¹ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ¨ªé•·ï¼‰ */
        .cost-table-wrapper {
            overflow-x: auto;
            margin: 0 -1rem;
            padding: 0 1rem;
        }
        
        .cost-table {
            width: 100%;
            min-width: 1000px;
            border-collapse: collapse;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.8rem;
        }
        
        .cost-table .header-group th {
            background: var(--bg-secondary);
            padding: 0.6rem 0.8rem;
            text-align: center;
            font-weight: 600;
            color: var(--text-primary);
            border-bottom: 1px solid var(--border-color);
            white-space: nowrap;
        }
        
        .cost-table .header-group .group-current {
            background: rgba(34, 211, 238, 0.15);
            color: var(--accent-cyan);
        }
        
        .cost-table .header-group .group-recommend {
            background: rgba(74, 222, 128, 0.15);
            color: var(--accent-green);
        }
        
        .cost-table .header-detail th {
            background: var(--bg-secondary);
            padding: 0.5rem 0.6rem;
            text-align: center;
            font-weight: 500;
            font-size: 0.75rem;
            color: var(--text-secondary);
            border-bottom: 2px solid var(--border-color);
            white-space: nowrap;
        }
        
        .cost-table td {
            padding: 0.6rem 0.8rem;
            border-bottom: 1px solid var(--border-color);
            text-align: center;
        }
        
        .cost-table tr:hover {
            background: rgba(34, 211, 238, 0.05);
        }
        
        .cost-table .name-cell {
            text-align: left;
            font-weight: 500;
            color: var(--text-primary);
            max-width: 200px;
            overflow: hidden;
            text-overflow: ellipsis;
        }
        
        .cost-table .id-cell {
            text-align: left;
            font-size: 0.7rem;
            color: var(--text-secondary);
        }
        
        .cost-table .num-cell {
            text-align: right;
        }
        
        .cost-table .money-cell {
            text-align: right;
            font-weight: 500;
            color: var(--accent-cyan);
        }
        
        .cost-table .recommend-cell {
            color: var(--accent-green);
            font-weight: 500;
        }
        
        .cost-table .savings-cell {
            font-weight: 600;
        }
        
        .cost-table .savings-cell.positive {
            color: var(--accent-green);
            background: rgba(74, 222, 128, 0.1);
        }
        
        .cost-table .ai-comment-cell {
            text-align: left;
            font-size: 0.75rem;
            color: var(--text-secondary);
            max-width: 150px;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }

        .analysis-card {
            background: var(--bg-card);
            border-radius: 20px;
            border: 1px solid var(--border-color);
            padding: 2rem;
            margin-top: 2rem;
        }

        .analysis-content {
            font-size: 1rem;
            line-height: 1.8;
            color: var(--text-secondary);
            white-space: pre-wrap;
        }

        .analysis-content strong {
            color: var(--accent-cyan);
        }

        .empty-state {
            text-align: center;
            padding: 3rem;
            color: var(--text-secondary);
        }

        .empty-state .icon {
            font-size: 3rem;
            margin-bottom: 1rem;
            opacity: 0.5;
        }

        .resource-cards {
            display: grid;
            gap: 1.5rem;
        }

        .resource-card {
            background: var(--bg-card);
            border-radius: 16px;
            border: 1px solid var(--border-color);
            overflow: hidden;
        }

        .resource-card-header {
            padding: 1rem 1.5rem;
            border-bottom: 1px solid var(--border-color);
            background: var(--bg-secondary);
        }

        .resource-card-body {
            overflow-x: auto;
        }

        .timestamp {
            font-size: 0.75rem;
            color: var(--text-secondary);
        }

        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }

            h1 {
                font-size: 1.8rem;
            }

            .button-group {
                flex-direction: column;
            }

            .btn {
                width: 100%;
                justify-content: center;
            }

            .data-table {
                font-size: 0.75rem;
            }

            .data-table th,
            .data-table td {
                padding: 0.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <div class="logo">
                <div class="logo-icon">ğŸ“Š</div>
                <h1>AWS ã‚¤ãƒ³ãƒ•ãƒ©ã‚³ã‚¹ãƒˆå‰Šæ¸›</h1>
            </div>
            <p class="subtitle">EC2ãƒ»RDSãƒ»ElastiCacheãƒ»DocumentDB ã®ã‚µã‚¤ã‚¸ãƒ³ã‚°æœ€é©åŒ–ææ¡ˆ</p>
        </header>

        <div class="main-card">
            <div class="button-group">
                <button class="btn btn-primary" onclick="runAnalysis()" id="analyzeBtn">
                    <span>ğŸ”</span>
                    åˆ†æã‚’å®Ÿè¡Œ
                </button>
                <button class="btn btn-secondary" onclick="clearResults()" id="clearBtn">
                    <span>ğŸ—‘ï¸</span>
                    çµæœã‚’ã‚¯ãƒªã‚¢
                </button>
            </div>

            <div class="status-bar" id="statusBar" style="display: none;">
                <div class="spinner"></div>
                <span id="statusText">å‡¦ç†ä¸­...</span>
            </div>
        </div>

        <div class="results-section" id="resultsSection">
            <div class="resource-cards" id="resourceCards">
                <!-- å‹•çš„ã«ç”Ÿæˆ -->
            </div>

            <div class="analysis-card" id="analysisCard" style="display: none;">
                <div class="section-title">
                    <div class="icon" style="background: linear-gradient(135deg, var(--accent-cyan), var(--accent-orange));">ğŸ¤–</div>
                    AI ã‚µã‚¤ã‚¸ãƒ³ã‚°ææ¡ˆ
                </div>
                <div class="analysis-content" id="analysisContent"></div>
            </div>
        </div>
    </div>

    <script>
        function getCpuClass(cpu) {
            if (cpu === null || cpu === undefined) return '';
            if (cpu < 40) return 'cpu-low';
            if (cpu < 70) return 'cpu-medium';
            return 'cpu-high';
        }

        function formatCpu(cpu) {
            if (cpu === null || cpu === undefined) return '-';
            return cpu.toFixed(2) + '%';
        }

        function formatTimestamp(ts) {
            if (!ts) return '-';
            const date = new Date(ts);
            return date.toLocaleString('ja-JP');
        }

        function showStatus(message, type) {
            const statusBar = document.getElementById('statusBar');
            const statusText = document.getElementById('statusText');
            statusBar.style.display = 'flex';
            statusBar.className = 'status-bar ' + type;
            statusText.textContent = message;
            
            if (type === 'loading') {
                statusBar.querySelector('.spinner').style.display = 'block';
            } else {
                statusBar.querySelector('.spinner').style.display = 'none';
            }
        }

        function hideStatus() {
            document.getElementById('statusBar').style.display = 'none';
        }

        // MCP ã‹ã‚‰å–å¾—ã—ãŸå‹•çš„ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        let mcpPricing = { ec2: {}, rds: {}, elasticache: {}, docdb: {} };
        
        // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®å›ºå®šä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        const FALLBACK_PRICES = {
            ec2: {
                't3.nano': 0.0052, 't3.micro': 0.0104, 't3.small': 0.0208, 't3.medium': 0.0416, 't3.large': 0.0832,
                't3a.nano': 0.0047, 't3a.micro': 0.0094, 't3a.small': 0.0188, 't3a.medium': 0.0376, 't3a.large': 0.0752,
                't4g.nano': 0.0042, 't4g.micro': 0.0084, 't4g.small': 0.0168, 't4g.medium': 0.0336, 't4g.large': 0.0672,
                'm5.large': 0.096, 'm5.xlarge': 0.192, 'm6i.large': 0.096,
                'c5.large': 0.085, 'c5.xlarge': 0.17, 'r5.large': 0.126
            },
            rds: {
                'db.t3.micro': 0.018, 'db.t3.small': 0.036, 'db.t3.medium': 0.072, 'db.t3.large': 0.144,
                'db.t4g.micro': 0.016, 'db.t4g.small': 0.032, 'db.t4g.medium': 0.065, 'db.t4g.large': 0.129,
                'db.r5.large': 0.25, 'db.r5.xlarge': 0.50, 'db.r6g.large': 0.218
            },
            elasticache: {
                'cache.t3.micro': 0.017, 'cache.t3.small': 0.034, 'cache.t3.medium': 0.068,
                'cache.t4g.micro': 0.016, 'cache.t4g.small': 0.032, 'cache.t4g.medium': 0.064,
                'cache.r5.large': 0.24, 'cache.r6g.large': 0.218
            },
            docdb: {
                'db.t3.medium': 0.072, 'db.r5.large': 0.25, 'db.r6g.large': 0.218
            }
        };
        
        const EBS_PRICES = { 'gp2': 0.10, 'gp3': 0.08, 'io1': 0.125, 'io2': 0.125, 'st1': 0.045, 'sc1': 0.025 };

        function getInstancePrice(type, service = 'ec2') {
            // ã¾ãšMCPã‹ã‚‰å–å¾—ã—ãŸä¾¡æ ¼ã‚’ãƒã‚§ãƒƒã‚¯
            const serviceKey = (service === 'redis' || service === 'memcache') ? 'elasticache' : service;
            if (mcpPricing[serviceKey] && mcpPricing[serviceKey][type]) {
                return mcpPricing[serviceKey][type];
            }
            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¾¡æ ¼ã‚’ä½¿ç”¨
            const fallbackKey = (service === 'redis' || service === 'memcache') ? 'elasticache' : service;
            if (FALLBACK_PRICES[fallbackKey] && FALLBACK_PRICES[fallbackKey][type]) {
                return FALLBACK_PRICES[fallbackKey][type];
            }
            // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¾¡æ ¼
            if (service === 'ec2') return 0.05;
            if (service === 'rds' || service === 'docdb') return 0.10;
            return 0.05;
        }
        
        function setPricingData(pricing) {
            if (pricing) {
                mcpPricing = pricing;
                console.log('MCP pricing data loaded:', Object.keys(pricing).map(k => `${k}: ${Object.keys(pricing[k]).length} types`).join(', '));
            }
        }
        
        function getEbsPrice(type) {
            return EBS_PRICES[type] || 0.08;
        }
        
        function formatMoney(amount) {
            if (amount === null || amount === undefined) return '-';
            return '$' + amount.toFixed(2);
        }

        function createCostTable(data, service, aiRecommendations) {
            if (!data || data.length === 0) {
                return '<div class="empty-state"><div class="icon">ğŸ“­</div><p>ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“</p></div>';
            }
            
            const isEc2 = service === 'ec2';
            const HOURS_PER_MONTH = 730;
            
            let html = '<div class="cost-table-wrapper"><table class="cost-table"><thead>';
            
            // ãƒ˜ãƒƒãƒ€ãƒ¼1è¡Œç›®ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—ï¼‰
            html += '<tr class="header-group">';
            html += '<th rowspan="2">åå‰</th>';
            if (isEc2) html += '<th rowspan="2">ID</th>';
            html += '<th colspan="' + (isEc2 ? '6' : '3') + '" class="group-current">ç¾çŠ¶</th>';
            html += '<th colspan="3" class="group-recommend">å¤‰æ›´ææ¡ˆ</th>';
            html += '<th rowspan="2">CPU AvgMax</th>';
            html += '<th rowspan="2">CPU Max</th>';
            html += '<th rowspan="2">AIã‚³ãƒ¡ãƒ³ãƒˆ</th>';
            html += '</tr>';
            
            // ãƒ˜ãƒƒãƒ€ãƒ¼2è¡Œç›®ï¼ˆè©³ç´°ï¼‰
            html += '<tr class="header-detail">';
            html += '<th>ã‚¿ã‚¤ãƒ—</th><th>å°æ•°</th><th>æœˆé¡</th>';
            if (isEc2) html += '<th>EBS</th><th>GB</th><th>EBSæ–™é‡‘</th>';
            html += '<th>ææ¡ˆã‚¿ã‚¤ãƒ—</th><th>æœˆé¡</th><th>å‰Šæ¸›é¡</th>';
            html += '</tr></thead><tbody>';
            
            data.forEach(item => {
                const name = item.name || '-';
                const instanceId = item.instance_id || '-';
                const instanceType = item.instance_type || '-';
                const count = item.count || 1;
                const ebsType = item.ebs_type || '-';
                const ebsSize = parseInt(item.ebs_size) || 0;
                const cpuAvgMax = item.cpu_avg_max;
                const cpuMax = item.cpu_max;
                
                // ç¾çŠ¶ã‚³ã‚¹ãƒˆè¨ˆç®—
                const hourlyPrice = getInstancePrice(instanceType, service);
                const monthlyInstance = hourlyPrice * HOURS_PER_MONTH * count;
                const monthlyEbs = isEc2 ? getEbsPrice(ebsType) * ebsSize * count : 0;
                const monthlyTotal = monthlyInstance + monthlyEbs;
                
                // AIææ¡ˆã‚’æ¤œç´¢
                const rec = aiRecommendations ? aiRecommendations.find(r => 
                    r.name === name || (item.instance_id && r.instance_id === item.instance_id)
                ) : null;
                
                const recType = rec ? rec.recommended_type : '-';
                const recPrice = rec && rec.recommended_type !== '-' ? getInstancePrice(rec.recommended_type, service) : null;
                const recMonthly = recPrice ? recPrice * HOURS_PER_MONTH * count + monthlyEbs : null;
                const savings = recMonthly !== null ? monthlyTotal - recMonthly : null;
                const aiComment = rec ? rec.note || (rec.recommended_type !== '-' ? 'å¤‰æ›´æ¨å¥¨' : 'å¤‰æ›´ä¸è¦') : '-';
                
                html += '<tr>';
                html += `<td class="name-cell">${name}</td>`;
                if (isEc2) html += `<td class="id-cell">${instanceId !== 'None' ? instanceId : '-'}</td>`;
                html += `<td>${instanceType}</td>`;
                html += `<td class="num-cell">${count}</td>`;
                html += `<td class="money-cell">${formatMoney(monthlyInstance)}</td>`;
                if (isEc2) {
                    html += `<td>${ebsType}</td>`;
                    html += `<td class="num-cell">${ebsSize || '-'}</td>`;
                    html += `<td class="money-cell">${ebsSize ? formatMoney(monthlyEbs) : '-'}</td>`;
                }
                html += `<td class="recommend-cell">${recType}</td>`;
                html += `<td class="money-cell">${recMonthly !== null ? formatMoney(recMonthly) : '-'}</td>`;
                html += `<td class="savings-cell ${savings > 0 ? 'positive' : ''}">${savings !== null && savings > 0 ? '-' + formatMoney(savings) + '/æœˆ' : '-'}</td>`;
                html += `<td><span class="cpu-badge ${getCpuClass(cpuAvgMax)}">${formatCpu(cpuAvgMax)}</span></td>`;
                html += `<td><span class="cpu-badge ${getCpuClass(cpuMax)}">${formatCpu(cpuMax)}</span></td>`;
                html += `<td class="ai-comment-cell">${aiComment}</td>`;
                html += '</tr>';
            });
            
            html += '</tbody></table></div>';
            return html;
        }

        function createTable(data, columns) {
            if (!data || data.length === 0) {
                return '<div class="empty-state"><div class="icon">ğŸ“­</div><p>ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“</p></div>';
            }

            let html = '<table class="data-table"><thead><tr>';
            columns.forEach(col => {
                html += `<th>${col.label}</th>`;
            });
            html += '</tr></thead><tbody>';

            data.forEach(item => {
                html += '<tr>';
                columns.forEach(col => {
                    let value = item[col.key];
                    if (col.key === 'cpu_avg_max' || col.key === 'cpu_max' || col.key === 'max_cpu') {
                        const cpuClass = getCpuClass(value);
                        html += `<td><span class="cpu-badge ${cpuClass}">${formatCpu(value)}</span></td>`;
                    } else if (col.key === 'timestamp' || col.key === 'max_cpu_time') {
                        html += `<td class="timestamp">${formatTimestamp(value)}</td>`;
                    } else {
                        html += `<td>${value ?? '-'}</td>`;
                    }
                });
                html += '</tr>';
            });

            html += '</tbody></table>';
            return html;
        }

        // ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
        let globalAiRecommendations = {};
        let globalResources = null;
        
        // AIåˆ†æçµæœã‹ã‚‰ææ¡ˆã‚’æŠ½å‡º
        function parseAiRecommendations(analysisText) {
            const recommendations = { ec2: [], rds: [], redis: [], memcache: [], docdb: [] };
            if (!analysisText) return recommendations;
            
            const lines = analysisText.split('\\n');
            let currentSection = null;
            let currentInstance = null;
            
            for (let i = 0; i < lines.length; i++) {
                const line = lines[i];
                
                // ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡º
                if (line.includes('### EC2')) currentSection = 'ec2';
                else if (line.includes('### RDS')) currentSection = 'rds';
                else if (line.includes('### DocumentDB')) currentSection = 'docdb';
                else if (line.includes('### Redis')) currentSection = 'redis';
                else if (line.includes('### Memcached')) currentSection = 'memcache';
                
                // ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åã‚’æ¤œå‡ºï¼ˆ**name**: å½¢å¼ï¼‰
                const nameMatch = line.match(/^-\\s*\\*\\*(?:ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å|ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å)?\\s*:?\\*\\*:?\\s*(.+)/);
                if (nameMatch && currentSection) {
                    currentInstance = {
                        name: nameMatch[1].trim().replace(/\\*\\*/g, ''),
                        recommended_type: '-',
                        note: '',
                        judgment: ''
                    };
                }
                
                // åˆ¤å®šè¡Œã‚’æ¤œå‡º
                if (currentInstance && line.includes('åˆ¤å®š:')) {
                    const judgmentMatch = line.match(/åˆ¤å®š:\\s*(.+)/);
                    if (judgmentMatch) {
                        const judgment = judgmentMatch[1].trim();
                        if (judgment.includes('éå‰°')) {
                            currentInstance.judgment = 'éå‰°ã‚¹ãƒšãƒƒã‚¯';
                        } else if (judgment.includes('é©æ­£')) {
                            currentInstance.judgment = 'é©æ­£';
                        } else if (judgment.includes('ä¸è¶³')) {
                            currentInstance.judgment = 'ã‚¹ãƒšãƒƒã‚¯ä¸è¶³';
                        }
                    }
                }
                
                // ææ¡ˆè¡Œã‚’æ¤œå‡º
                if (currentInstance && line.includes('ææ¡ˆ:')) {
                    const proposalMatch = line.match(/ææ¡ˆ:\\s*(.+)/);
                    if (proposalMatch) {
                        const proposal = proposalMatch[1].trim();
                        
                        // ã‚¹ãƒšãƒƒã‚¯ä¸è¶³ã®å ´åˆã¯å¤‰æ›´ææ¡ˆã—ãªã„ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã®ã¿ï¼‰
                        if (currentInstance.judgment === 'ã‚¹ãƒšãƒƒã‚¯ä¸è¶³') {
                            currentInstance.recommended_type = '-';
                            currentInstance.note = 'ã‚¹ãƒšãƒƒã‚¯ä¸è¶³';
                        } else if (proposal.includes('å¤‰æ›´ä¸è¦') || proposal.includes('ç¶­æŒ')) {
                            currentInstance.note = currentInstance.judgment || 'é©æ­£';
                        } else {
                            // ã‚¿ã‚¤ãƒ—æŠ½å‡º (t3.medium, db.t3.medium, cache.t3.medium ãªã©) - ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã®ã¿
                            const typeMatch = proposal.match(/((?:db\\.|cache\\.)?[a-z][a-z0-9]*\\.[a-z0-9]+)/i);
                            if (typeMatch) {
                                currentInstance.recommended_type = typeMatch[1];
                                currentInstance.note = currentInstance.judgment || 'éå‰°ã‚¹ãƒšãƒƒã‚¯';
                            } else {
                                currentInstance.note = currentInstance.judgment || proposal.substring(0, 20);
                            }
                        }
                        
                        // ç¾åœ¨ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«è¿½åŠ 
                        if (currentSection && currentInstance.name) {
                            recommendations[currentSection].push({...currentInstance});
                        }
                        currentInstance = null;
                    }
                }
            }
            
            return recommendations;
        }

        function renderResources(resources, aiRecommendations = null) {
            const container = document.getElementById('resourceCards');
            container.innerHTML = '';

            // ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«ä¿å­˜
            globalResources = resources;
            if (aiRecommendations) {
                globalAiRecommendations = aiRecommendations;
            }

            const sections = [
                { key: 'ec2', title: 'EC2 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹', emoji: 'ğŸ’»' },
                { key: 'rds', title: 'RDS ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼', emoji: 'ğŸ—„ï¸' },
                { key: 'redis', title: 'Redis (ElastiCache)', emoji: 'âš¡' },
                { key: 'memcache', title: 'Memcached (ElastiCache)', emoji: 'ğŸš€' },
                { key: 'docdb', title: 'DocumentDB', emoji: 'ğŸ“‘' }
            ];

            sections.forEach(section => {
                const data = resources[section.key];
                if (data && data.length > 0) {
                    const recs = globalAiRecommendations[section.key] || [];
                    const card = document.createElement('div');
                    card.className = 'resource-card';
                    card.innerHTML = `
                        <div class="resource-card-header">
                            <div class="section-title">
                                <div class="icon ${section.key}">${section.emoji}</div>
                                ${section.title}
                                <span style="color: var(--text-secondary); font-weight: 400; font-size: 0.9rem;">(${data.length}ä»¶)</span>
                            </div>
                        </div>
                        <div class="resource-card-body">
                            ${createCostTable(data, section.key, recs)}
                        </div>
                    `;
                    container.appendChild(card);
                }
            });

            document.getElementById('resultsSection').classList.add('visible');
        }

        function renderAnalysis(text, tokenUsage = null) {
            const card = document.getElementById('analysisCard');
            const content = document.getElementById('analysisContent');
            content.textContent = text;
            card.style.display = 'block';
            
            // AIææ¡ˆã‚’æŠ½å‡ºã—ã¦ãƒªã‚½ãƒ¼ã‚¹è¡¨ç¤ºã‚’æ›´æ–°
            const recommendations = parseAiRecommendations(text);
            if (globalResources) {
                renderResources(globalResources, recommendations);
            }
            
            // ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¡¨ç¤º
            let costHtml = document.getElementById('tokenUsageInfo');
            if (!costHtml) {
                costHtml = document.createElement('div');
                costHtml.id = 'tokenUsageInfo';
                costHtml.style.cssText = 'margin-top: 1rem; padding: 0.75rem 1rem; background: var(--bg-secondary); border-radius: 6px; font-size: 0.85rem; color: var(--text-secondary); display: flex; gap: 1.5rem; flex-wrap: wrap;';
                card.appendChild(costHtml);
            }
            
            if (tokenUsage) {
                const inputTokens = tokenUsage.input_tokens || 0;
                const outputTokens = tokenUsage.output_tokens || 0;
                const totalTokens = tokenUsage.total_tokens || 0;
                const costUsd = tokenUsage.total_cost_usd || 0;
                const costJpy = tokenUsage.total_cost_jpy || 0;
                
                costHtml.innerHTML = `
                    <span>ğŸ“Š <strong>ãƒˆãƒ¼ã‚¯ãƒ³:</strong> ${inputTokens.toLocaleString()} in + ${outputTokens.toLocaleString()} out = ${totalTokens.toLocaleString()} total</span>
                    <span>ğŸ’° <strong>ã‚³ã‚¹ãƒˆ:</strong> $${costUsd.toFixed(6)} (ç´„${costJpy.toFixed(4)}å††)</span>
                    <span>ğŸ¤– <strong>ãƒ¢ãƒ‡ãƒ«:</strong> ${tokenUsage.model_id || 'N/A'}</span>
                `;
                costHtml.style.display = 'flex';
            } else {
                costHtml.style.display = 'none';
            }
        }

        async function runAnalysis() {
            const analyzeBtn = document.getElementById('analyzeBtn');
            analyzeBtn.disabled = true;

            try {
                showStatus('AWSãƒªã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’åé›†ä¸­...', 'loading');
                
                const response = await fetch(window.location.href, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ action: 'analyze' })
                });

                if (!response.ok) {
                    throw new Error('API request failed');
                }

                const data = await response.json();
                
                // MCP ã‹ã‚‰å–å¾—ã—ãŸä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
                if (data.pricing) {
                    setPricingData(data.pricing);
                }
                
                showStatus('ãƒªã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’è¡¨ç¤ºä¸­...', 'loading');
                renderResources(data.resources);

                if (data.analysis) {
                    renderAnalysis(data.analysis, data.token_usage);
                }

                showStatus('åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ', 'success');
                setTimeout(hideStatus, 3000);

            } catch (error) {
                console.error('Error:', error);
                showStatus('ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ' + error.message, 'error');
            } finally {
                analyzeBtn.disabled = false;
            }
        }

        function clearResults() {
            document.getElementById('resourceCards').innerHTML = '';
            document.getElementById('analysisCard').style.display = 'none';
            document.getElementById('resultsSection').classList.remove('visible');
            hideStatus();
        }

        // ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿æ™‚ã®å‡¦ç†
        document.addEventListener('DOMContentLoaded', function() {
            console.log('Page loaded');
        });
    </script>
</body>
</html>'''


def lambda_handler(event, context):
    """Lambdaé–¢æ•°ã®ãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    
    # Function URLã‹ã‚‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†
    http_method = event.get('requestContext', {}).get('http', {}).get('method', 'GET')
    
    # CORSãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–å«ã‚€ï¼‰
    headers = {
        'Content-Type': 'text/html; charset=utf-8',
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
        'Access-Control-Allow-Headers': 'Content-Type',
        'Cache-Control': 'no-cache, no-store, must-revalidate',
        'Pragma': 'no-cache',
        'Expires': '0'
    }
    
    # OPTIONSãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆCORS preflightï¼‰
    if http_method == 'OPTIONS':
        return {
            'statusCode': 200,
            'headers': headers,
            'body': ''
        }
    
    # GETãƒªã‚¯ã‚¨ã‚¹ãƒˆ - HTMLã¾ãŸã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’è¿”ã™
    if http_method == 'GET':
        # ãƒ‘ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
        path = event.get('rawPath', '') or event.get('requestContext', {}).get('http', {}).get('path', '')
        
        # é€šå¸¸ã®HTMLãƒšãƒ¼ã‚¸
        return {
            'statusCode': 200,
            'headers': headers,
            'body': get_html_template()
        }
    
    # POSTãƒªã‚¯ã‚¨ã‚¹ãƒˆ - åˆ†æã‚’å®Ÿè¡Œ
    if http_method == 'POST':
        headers['Content-Type'] = 'application/json'
        
        try:
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚’ãƒ‘ãƒ¼ã‚¹
            body = {}
            if event.get('body'):
                body = json.loads(event['body']) if isinstance(event['body'], str) else event['body']
            
            # ãƒªã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’åé›†
            resources = collect_all_resources()
            
            # MCP ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ä¾¡æ ¼æƒ…å ±ã‚’å–å¾—
            pricing_info = collect_pricing_info(resources)
            
            # Bedrockç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆä¾¡æ ¼æƒ…å ±å«ã‚€ï¼‰
            resource_text = format_resources_for_bedrock(resources, pricing_info)
            
            # Bedrockã§åˆ†æ
            analysis_result = get_bedrock_analysis(resource_text)
            
            return {
                'statusCode': 200,
                'headers': headers,
                'body': json.dumps({
                    'resources': resources,
                    'pricing': pricing_info,
                    'analysis': analysis_result['text'],
                    'token_usage': analysis_result['token_usage']
                }, ensure_ascii=False, default=str)
            }
            
        except Exception as e:
            return {
                'statusCode': 500,
                'headers': headers,
                'body': json.dumps({
                    'error': str(e)
                }, ensure_ascii=False)
            }
    
    # ãã®ä»–ã®ãƒ¡ã‚½ãƒƒãƒ‰
    return {
        'statusCode': 405,
        'headers': headers,
        'body': 'Method Not Allowed'
    }

